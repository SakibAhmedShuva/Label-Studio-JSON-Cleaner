{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file: d:\\OneDrive - Personal\\FleetBlox\\Data\\Driving Licences\\Final Json\\combined_data.json\n",
      "\n",
      "=== Special Characters Analysis Report ===\n",
      "\n",
      "Character  Count    Unicode Name                   Category   Hex Value \n",
      "----------------------------------------------------------------------\n",
      "Ã          187      LATIN CAPITAL LETTER A WITH TI Lu         0xc3      \n",
      "           101      NO-BREAK SPACE                 Zs         0xa0      \n",
      "Â          75       LATIN CAPITAL LETTER A WITH CI Lu         0xc2      \n",
      "©          58       COPYRIGHT SIGN                 So         0xa9      \n",
      "ƒ          55       LATIN SMALL LETTER F WITH HOOK Ll         0x192     \n",
      "‰          18       PER MILLE SIGN                 Po         0x2030    \n",
      "â          9        LATIN SMALL LETTER A WITH CIRC Ll         0xe2      \n",
      "¬          8        NOT SIGN                       Sm         0xac      \n",
      "€          8        EURO SIGN                      Sc         0x20ac    \n",
      "¢          7        CENT SIGN                      Sc         0xa2      \n",
      "š          7        LATIN SMALL LETTER S WITH CARO Ll         0x161     \n",
      "§          5        SECTION SIGN                   Po         0xa7      \n",
      "¨          4        DIAERESIS                      Sk         0xa8      \n",
      "‡          4        DOUBLE DAGGER                  Po         0x2021    \n",
      "‚          3        SINGLE LOW-9 QUOTATION MARK    Ps         0x201a    \n",
      "´          1        ACUTE ACCENT                   Sk         0xb4      \n",
      "ª          1        FEMININE ORDINAL INDICATOR     Lo         0xaa      \n",
      "¡          1        INVERTED EXCLAMATION MARK      Po         0xa1      \n",
      "ˆ          1        MODIFIER LETTER CIRCUMFLEX ACC Lm         0x2c6     \n",
      "\n",
      "Detailed report saved to 'special_chars_report.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "\n",
    "def analyze_special_characters(text):\n",
    "    \"\"\"\n",
    "    Analyze text for special characters and potential encoding issues\n",
    "    \"\"\"\n",
    "    # Find all non-ASCII characters\n",
    "    special_chars = re.findall(r'[^\\x00-\\x7F]+', text)\n",
    "    \n",
    "    # Create counter for special characters\n",
    "    char_counter = Counter(''.join(special_chars))\n",
    "    \n",
    "    # Analyze each character\n",
    "    char_analysis = []\n",
    "    for char, count in char_counter.items():\n",
    "        try:\n",
    "            name = unicodedata.name(char)\n",
    "            category = unicodedata.category(char)\n",
    "            hex_val = hex(ord(char))\n",
    "            char_analysis.append({\n",
    "                'character': char,\n",
    "                'count': count,\n",
    "                'unicode_name': name,\n",
    "                'category': category,\n",
    "                'hex_value': hex_val\n",
    "            })\n",
    "        except ValueError:\n",
    "            # Handle characters that can't be identified\n",
    "            char_analysis.append({\n",
    "                'character': char,\n",
    "                'count': count,\n",
    "                'unicode_name': 'UNKNOWN',\n",
    "                'category': 'UNKNOWN',\n",
    "                'hex_value': hex(ord(char))\n",
    "            })\n",
    "    \n",
    "    return char_analysis\n",
    "\n",
    "def find_special_chars_in_json(json_file):\n",
    "    \"\"\"\n",
    "    Find all special characters in a Label Studio JSON file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read JSON file\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Store all text content\n",
    "        all_text = []\n",
    "        \n",
    "        def extract_text(obj):\n",
    "            \"\"\"Recursively extract all text from JSON structure\"\"\"\n",
    "            if isinstance(obj, dict):\n",
    "                for value in obj.values():\n",
    "                    extract_text(value)\n",
    "            elif isinstance(obj, list):\n",
    "                for item in obj:\n",
    "                    extract_text(item)\n",
    "            elif isinstance(obj, str):\n",
    "                all_text.append(obj)\n",
    "        \n",
    "        # Extract all text from the JSON\n",
    "        extract_text(data)\n",
    "        \n",
    "        # Combine all text and analyze\n",
    "        combined_text = ' '.join(all_text)\n",
    "        analysis_results = analyze_special_characters(combined_text)\n",
    "        \n",
    "        # Sort by frequency\n",
    "        analysis_results.sort(key=lambda x: x['count'], reverse=True)\n",
    "        \n",
    "        return analysis_results\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error processing file: {str(e)}\"\n",
    "\n",
    "def print_analysis_report(analysis_results):\n",
    "    \"\"\"\n",
    "    Print a formatted report of special characters found\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Special Characters Analysis Report ===\\n\")\n",
    "    print(f\"{'Character':<10} {'Count':<8} {'Unicode Name':<30} {'Category':<10} {'Hex Value':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for result in analysis_results:\n",
    "        print(f\"{result['character']:<10} {result['count']:<8} {result['unicode_name'][:30]:<30} \"\n",
    "              f\"{result['category']:<10} {result['hex_value']:<10}\")\n",
    "\n",
    "def main():\n",
    "    # Replace with your JSON file path\n",
    "    json_file = r\"d:\\OneDrive - Personal\\FleetBlox\\Data\\Driving Licences\\Final Json\\combined_data.json\"\n",
    "    \n",
    "    print(f\"Analyzing file: {json_file}\")\n",
    "    results = find_special_chars_in_json(json_file)\n",
    "    \n",
    "    if isinstance(results, str):\n",
    "        print(f\"Error: {results}\")\n",
    "    else:\n",
    "        print_analysis_report(results)\n",
    "        \n",
    "        # Save results to a file\n",
    "        with open('special_chars_report.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "        print(\"\\nDetailed report saved to 'special_chars_report.json'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned file and saved to cleaned_label_studio_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def create_replacement_map():\n",
    "    \"\"\"\n",
    "    Creates a mapping of special characters to their replacements.\n",
    "    Each special character is mapped to a single character to maintain string length.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'Ã¢â€šÂ¬': '   ',\n",
    "        'ÃƒÂ': ' ',\n",
    "        'Ãƒâ€¡': '  ',\n",
    "        'Ãƒ': ' ',\n",
    "        # 'â€': 'A',\n",
    "        # 'šA': 'A',\n",
    "        # 'šA': 'A',\n",
    "        '¬': '-',\n",
    "        'Â': 'A',\n",
    "        'Ã': 'A',\n",
    "        'Â': 'A',\n",
    "        # '©': 'c',\n",
    "        # 'ƒ': 'f',\n",
    "        # '‰': '%',\n",
    "        'â': 'a',\n",
    "        # '¬': '-',\n",
    "        # '€': 'E',\n",
    "        # '¢': 'c',\n",
    "        # 'š': 's',\n",
    "        # '§': 'S',\n",
    "        # '¨': 'e',\n",
    "        # '‡': '+',\n",
    "        # '‚': ',',\n",
    "        # '´': \"'\",\n",
    "        # 'ª': 'a',\n",
    "        # '¡': 'i',\n",
    "        # 'ˆ': '^'\n",
    "    }\n",
    "\n",
    "def clean_text_preserve_length(text, char_map):\n",
    "    \"\"\"\n",
    "    Cleans text by replacing special characters while maintaining string length.\n",
    "    \"\"\"\n",
    "    for special_char, replacement in char_map.items():\n",
    "        text = text.replace(special_char, replacement)\n",
    "    return text\n",
    "\n",
    "def process_annotations(data):\n",
    "    \"\"\"\n",
    "    Processes the Label Studio JSON data, cleaning text while preserving annotation positions.\n",
    "    \"\"\"\n",
    "    char_map = create_replacement_map()\n",
    "    \n",
    "    # Process each item in the data\n",
    "    for item in data:\n",
    "        # Clean the text in the data section\n",
    "        if 'data' in item and 'text' in item['data']:\n",
    "            item['data']['text'] = clean_text_preserve_length(item['data']['text'], char_map)\n",
    "            \n",
    "        # Update the text in annotations if present\n",
    "        if 'annotations' in item:\n",
    "            for annotation in item['annotations']:\n",
    "                if 'result' in annotation:\n",
    "                    for result in annotation['result']:\n",
    "                        if 'value' in result and 'text' in result['value']:\n",
    "                            result['value']['text'] = clean_text_preserve_length(\n",
    "                                result['value']['text'], \n",
    "                                char_map\n",
    "                            )\n",
    "    return data\n",
    "\n",
    "def clean_label_studio_file(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Main function to clean the Label Studio JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read input file\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Process the data\n",
    "        cleaned_data = process_annotations(data)\n",
    "        \n",
    "        # Write output file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(cleaned_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        print(f\"Successfully cleaned file and saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = r\"d:\\OneDrive - Personal\\FleetBlox\\Data\\Driving Licences\\Final Json\\Final Combined_Edited.json\"\n",
    "    output_file = \"cleaned_label_studio_data.json\"\n",
    "    clean_label_studio_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
